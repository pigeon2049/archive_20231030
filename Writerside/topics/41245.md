# 打造生成式AI应用，什么才是关键？
**科技云报到**

**2023-10-30 12:02**

**https://www.qianzhan.com/analyst/detail/329/231030-b9e0270b.html**

![1](https://img3.qianzhan.com/news/202310/30/20231030-fcf769af13725f14_760x5000.jpg)

图源：摄图网

作者|科技云报道 来源|科技云报到(ID：ITCloud-BD)

生成式AI作为当前人工智能的前沿领域，全球多家科技企业都在加大生成式AI的研发投入力度。

随着技术、产品及应用等方面不断推出重要成果，如今有更多的行业用户在思考该如何将生成式AI应用落地。

但开发生成式AI应用是一个充满挑战的系统工程，并不是单纯的产品和服务拼接，涉及基础设施领域一系列的挑战。

亚马逊云科技大中华区产品部总经理陈晓建表示，当我们谈论生成式AI时，大多数人都在谈论基础模型，而整个生成式AI应用就像是浮在海面的冰山，露在海面上方能被大多数人看到的冰山一角就像是基础模型，而在冰川的底部，同样需要大量的基础模型以外的服务来支撑，如加速芯片、数据库、数据分析、数据安全服务等等。

那么，想要构建一个成功的生成式AI应用，需要哪些基础设施助力？业界是否有一些最佳实践可以参考呢？

 **01**

**生成式AI应用构建的关键**

**高性价比的基础设施**

都说算力、算法和数据是人工智能发展的三要素，想要让这些要素更好地与生成式AI应用匹配，高性价比的基础设施必不可少。

人工智能的发展从深度学习时代进入到大模型时代，大规模预训练模型的参数量呈现指数级上升，需要高性能算力的支撑。

目前，大规模预训练模型训练算力是以往的10到100倍，当前主流生成式AI模型的训练广泛使用到英伟达Tensor Core GPU芯片，如微软斥资数亿美元购买数万颗英伟达A100芯片以帮助Open AI打造ChatGPT。

AI计算集群能够提供大规模算力、持续提高算力资源利用率、提升数据存储和处理能力，进一步降低模型训练门槛和成本，推动生成式AI模型的落地进程。

当前较为典型的AI计算集群，例如基于英伟达最新GPU芯片H100 Tensor Core的Amazon EC2 P5实例，与上一代相比速度快6倍，训练成本节省40%；

基于亚马逊云科技自研的机器学习推理芯片Amazon Inferentia2推出的Amazon EC2 Inf2实例，与其他类似的EC2实例相比性价比高40%；

基于自研机器学习训练芯片Amazon Trainium推出的Amazon EC2 Trn1实例，与同类实例相比训练成本节省高达50%。

这也是为什么有越来越多的客户，比如Airbnb、OPPO、Sprinklr 和 Autodesk等，会选择使用亚马逊云科技的自研芯片来承载他们的生成式AI应用。

生成式AI的核心是利用机器学习领域的基础模型驱动的，从RNN、CNN到VAE、GAN，每种模型都有其独特的优点和应用领域，这些模型在很大程度上决定了AI系统的表现。

然而，基础模型的发展和迭代速度正超越以外任何一项技术，基本以月甚至天为单位持续迭代。

在众多的基础模型中，应该如何便捷安全的选择最适合自己业务场景的基础模型，是每一家企业在构建生成式AI应用时面临的挑战。

事实上，借助专门构建的生成式AI工具和基础设施，可以帮助企业快速构建高性价比的生成式AI应用。

例如，亚马逊云科技Amazon Bedrock是一项无服务器服务，提供了广泛的模型选择、数据隐私，并且能够自定义模型，无需管理任何基础设施。

该服务提供的基础模型来自Meta, Anthropic, Stability AI, AI21 Labs, Cohere等第三方领先提供商以及自身的Amazon Titan模型等，近期还加入了Meta的下一代开源大模型Llama2以及Anthropic的Claude2等热门基础模型。

同时，Amazon Bedrock与Amazon SageMaker Jumpstart结合，用户可以从Amazon SageMaker Jumpstart中选择开源的基础模型，然后根据自身需求可以选择全量微调，轻量微调等不同方式，进一步确定微调框架，利用分布式训练实现微调，从而更好的评估微调效果。

人工智能预训练模型的开发对于云服务有较大需求，AI云服务可以提供人工智能开发模块，通过多元化的服务模式，降低开发者的开发成本和产品开发周期，为模型开发提供AI赋能。

尤其是借助云原生服务，可以加速AI应用构建，助力业务敏捷创新。

比如，以微服务化和事件驱动架构为核心的设计框架，松耦合的去处理每个功能模块之间的互相依赖；Serverless First能够简化运维、提升效率；在DevOps、基础设施即服务、自动化等现代应用治理理念持续投入，可以促进企业内部的应用资产与实践的分享，构建高效敏捷的构建者文化等等。

数据作为生成式AI的关键，也将推动生成式AI的广泛应用，对于所有的组织企业来说都十分重要。

首先，面向生成式AI构建强大的数据“基座”，需要一套全面的服务，以便能够存储用于构建和微调模型的各种类型的数据；

其次，还需要服务间的集成，以打破数据孤岛，确保能够随时访问所有数据；

最后，还需要在构建生成式AI应用程序的整个生命周期中，确保数据安全并对其进行管理。

以亚马逊云科技为例，针对生成式AI领域的用户个人信息、会话信息管理、私域知识库等应用场景都提供了专门构建的数据库。

在数据集成方面，亚马逊云科技已经在Amazon S3、Amazon Aurora、Amazon Redshift、Amazon SageMaker、Amazon EMR、Amazon Athena、Amazon Kinesis等各项服务之间，实现了深度的数据集成，帮助企业执行分析和机器学习，且无需移动数据。

在数据治理方面，亚马逊云科技Amazon DataZone让客户能够跨组织边界发现、访问、共享和治理大规模数据，并减少企业内部成员访问数据和使用分析工具时繁重的工作量。

02

****构建生成式AI****

****应用的行业实践****

目前，由生成式AI引导的企业变革序幕全面展开，以多元应用不断创新AI应用范式，并将实践成果逐步延伸至智慧教育、智能制造、医疗等领域，真正成为人们生产生活的得力助手。

其中，在行业类应用场景中，AI助手类应用得到了广泛运用，比如在协同办公赛道就掀起了新风口：

钉钉接入千问大模型，用户可以唤起10余项AI能力如：自动整理群聊要点、生成待办、预约日程、写文案、生成海报、一键生成讨论要点等。

飞书宣布推出智能助手“My AI”，功能包括汇总会议纪要、创建报告、优化和续写文字内容等功能。

金山办公推出“WPS AI”，支持内容生成、公式生成、制作PPT、扫描识别并分析文件等功能。

而在金融、医疗、工业等领域，最具前景的应用则来自于数据挖掘和知识洞察（Insight）类工具。

但无论是哪种形式的生成式AI的应用落地，背后都离不开强大的基础设施作为支撑。

金山办公软件股份有限公司的 AI 研发总监刘强表示，今年起WPS开始将大语言模型的能力全面引入产品，致力于开发新一代办公软件。

而在构建生成式AI应用的过程中，基础模型性能有限，数据隐私与安全难以保障，高额管理成本等现实情况成为了摆在金山办公面前的重重障碍。

亚马逊云科技Amazon Bedrock中支持的领先大语言模型，在多个文字处理场景中符合金山办公的需求。

除多种模型选择外，Amazon Bedrock还在数据安全层面给金山办公提供了充分的支持，极大地提高了金山办公的内部开发效率，助力金山办公进一步革新办公体验。

西门子中国也借助了一系列云基础设施、大数据、机器学习等技术，来构建生成式AI应用。

据西门子中国大禹团队介绍，长期以来企业内部资源的检索和调用都存在结构散乱、检索速度慢、交互不便等问题。因此，大禹团队决定将大数据库和生成式 AI 应用于一个全新的“智能知识库”，从根本上提升知识库的可用性。

在亚马逊云的技术支持下，西门子中国大禹团队通过一个智能知识库暨智能会话机器人的解决方案，三个月时间就上线了生成式AI对话机器人“小禹”，实现了快速、精准的查询和回复。

在整个解决方案中，包括预训练大语言模型，Amazon OpenSearch Service的向量数据服务，以及相关系统集成等，这些核心关键能力让解决方案指南能实现目标知识库约80%功能，西门子中国根据企业内部需求再做20%定制化开发，最终形成完整的解决方案。

同时，Amazon OpenSearch Service的无服务器特性，让开发人员不需要管理集群或担心生产规模，可以快速推动部署。

基于Amazon SageMaker上提供的丰富的模型开发和训练工具，也保证了开发人员可以在云端轻松实现大语言模型的调优以及测试更多不同类型的开源模型。

03

**结语**

生成式AI正在成为企业新一轮业务创新的重要工具，成为下一代的生产力工具。

总体来看，高性价比的云基础设施技术如同一艘航母，能够为企业提供坚实的底座，让企业摆脱基础设施的束缚，更好、更高效地专注于创新。

编者按：本文转载自微信公众号：科技云报到(ID：ITCloud-BD)，作者：科技云报道